{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things that still need to be added:<br>\n",
    "\n",
    "Changes to the code/methods/similar:<br>\n",
    "    -Add a log with the output:<br>\n",
    "        -Final values<br>\n",
    "        -The output log needs some organization work<br>\n",
    "        -JHK fits (see below, this might not be worth it) <br>\n",
    "        -EBV priors from dust maps https://vizier.u-strasbg.fr/viz-bin/VizieR?-source=J/A%2BA/625/A135 ?<br>\n",
    "        &nbsp;&nbsp; &nbsp;&nbsp;https://stilism.obspm.fr/scripts <br>\n",
    "        -Bayestar19 for north  of -30?\n",
    "    \n",
    "Make plots look cooler:<br>\n",
    "    -Make points smaller if there are a lot, bigger if few (point size scaling)<br>\n",
    "    -Better use of alpha when plotting lots of points?<br>\n",
    "    -Quite a bit of whitespace to fill?<br>\n",
    "    -Add reddening vector?<br>\n",
    "   \n",
    "\n",
    "Tests to run:<br>\n",
    "    -Other datasets with established ages (beta pic?)<br>\n",
    "    ~&nbsp;&nbsp;-MELANGE-1 (240+/-40, consistent with published)~<br>\n",
    "    ~&nbsp;&nbsp;-LCC groups (Getting consistent ages between Kerr and Goldman)~<br>\n",
    "    &nbsp;&nbsp;-Pleiades<br>\n",
    "\n",
    "Have to wait for help:<br>\n",
    "    -Updates for edr3 from Feiden<br>\n",
    "\n",
    "Long-term:<br>\n",
    "    -Fitting many mangitudes instead if just one sequence (i.e., P(G,Bp,Rp,J,H,K|age) = )<br>\n",
    "      Note: the way to do this is to give the input as a distance (or plx) and age, and then compute a given set of apparent magnitudes predicted by the model. What does the outlier distribution look like then? Is there an outlier distribution for each magnitude? <br>\n",
    "       Update: this is problematic for a lot of reasons. A big one is that Gaia is resolving out a lot of binaries that 2MASS is not... I think this is more effort than it's worth. <br>\n",
    "    -Don't bother with JHK for similar reasons, but also because of the cross-match issue<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = \"retina\"\n",
    "%matplotlib inline\n",
    "from matplotlib import rcParams\n",
    "rcParams[\"savefig.dpi\"] = 100\n",
    "rcParams[\"figure.dpi\"] = 100\n",
    "rcParams[\"font.size\"] = 20\n",
    "from astroquery.vizier import Vizier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "#from isochrones.interp import DFInterpolator\n",
    "import numpy.random as random\n",
    "import emcee\n",
    "import corner\n",
    "import random\n",
    "import scipy.integrate as integrate\n",
    "from scipy import interpolate\n",
    "from scipy import optimize\n",
    "import math as math\n",
    "from astroquery.mast import Catalogs\n",
    "from astroquery.gaia import Gaia\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "import multiprocessing\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "from multiprocessing import cpu_count\n",
    "plt.rcParams['lines.linewidth']   =3\n",
    "plt.rcParams['axes.linewidth']    = 2\n",
    "plt.rcParams['xtick.major.width'] =2\n",
    "plt.rcParams['ytick.major.width'] =2\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 15\n",
    "plt.rcParams['legend.numpoints'] = 1\n",
    "plt.rcParams['axes.labelweight']='semibold'\n",
    "plt.rcParams['mathtext.fontset']='stix'\n",
    "plt.rcParams['font.weight'] = 'semibold'\n",
    "plt.rcParams['axes.titleweight']='semibold'\n",
    "plt.rcParams['axes.titlesize']=9\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently have 3 run types:<br>\n",
    "-Normal: good for if the major interlopers are field M dwarfs (most common situation)<br>\n",
    "-Binary: good if membership list is solid but binaries are an issue<br>\n",
    "-Hybrid: good for a mix, models outliers as offset from the isochrone in any direction. Most reliable method <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make some basic decisions about the fit\n",
    "\n",
    "voffcut = 100 ## make this 100 if you don't know what it is\n",
    "\n",
    "## options are feiden_mag, feiden_std for now. Note that Feiden is DR2, and not suggested.\n",
    "usegrid = 'parsec'#'parsec'#feiden_mag' \n",
    "fittype = 'hybrid' ## options are normal, binary, and hybrid. See above\n",
    "ruwecut = 1.3 ## use 1.2 (agressive) to remove binaries, increase to 1.3--1.4 if more stars are needed\n",
    "filetype = 'radec' ### radec or kraus. This is meant for reading in the file. just use radec\n",
    "\n",
    "## it's going to look for a file called datafile.txt. I know, datafile.txt is probably a csv... \n",
    "## Listen, I'm a professor, not a programmer. Deal with it. \n",
    "datafile = 'TOI1227'\n",
    "#'hd109833_banyan_v2_hp'#'KOI-3876'#''HD109833'#'KOI-3876'#'cut_candidates'#'HD109833'\n",
    "\n",
    "##I think this is just for plot labeling? \n",
    "targname = 'TOI1227'#'KOI-3876'#'HD109833'#'KOI-3876'#\n",
    "#targcoord = SkyCoord(ra=290.44062871256, dec=38.52357232315, unit=(u.degree, u.degree), frame='icrs')##3876\n",
    "targcoord = SkyCoord(ra=186.7673449, dec=-72.4518516,unit=(u.degree, u.degree), frame='icrs')##toi1227\n",
    "#targcoord = SkyCoord(ra=341.9709064, dec=49.9180719, unit=(u.degree, u.degree), frame='icrs')\n",
    "#targcoord = SkyCoord(ra=189.77583262267967, dec=-74.57402138790371, unit=(u.degree, u.degree), frame='icrs')\n",
    "\n",
    "#This will be the name of the folder with the data. Useful if running targets with different settings. \n",
    "foldername = 'TOI1227'\n",
    "\n",
    "## don't change this\n",
    "whichgaia = 'edr3' ## source of colors and mags from Gaia (not relevant if using 2mass only)\n",
    "\n",
    "##bprp or grp. I've got better fits with grp, but I often run both to make sure I'm not doing something stupid. \n",
    "usecol = 'grp' ## color\n",
    "usemag = 'g' ## mag\n",
    "\n",
    "##Lol, what a mess... \n",
    "file_endian = fittype+'_'+usegrid+'_'+usecol+'_'+usemag+'_'+whichgaia ## will be used for output file names\n",
    "\n",
    "## the code only grabs the relevant part of models (to save runtime)\n",
    "## So this actually needs to be within a factor of a few or it grabs the wrong model grids.\n",
    "guessage = 10 ## Myr;\n",
    "burn=     5000\n",
    "nsteps = 50000\n",
    "## the code will output a note saying it didn't converge if this isn't large enough. I've found 5-10k steps is usually good\n",
    "\n",
    "## these are for plotting. \n",
    "if usecol == 'grp':\n",
    "    xlabel = r'$G - R_P$ (mag)'\n",
    "    colrange = [-0.15,1.5]\n",
    "if usecol == 'bprp':\n",
    "    xlabel = r'$B_P - R_P$ (mag)'\n",
    "    colrange = [-0.2,4]\n",
    "if usecol == 'gj':\n",
    "    xlabel = r'$G - J$ (mag)'\n",
    "    colrange = [-0.2,4]##??\n",
    "if usecol == 'jk':\n",
    "    xlabel = r'$J - K$ (mag)'\n",
    "    colrange = [-0.1,1.3]##??\n",
    "if usemag == 'g':\n",
    "    ylabel = r'$M_G$ (mag)'\n",
    "    magrange = [13.5,0]\n",
    "if usemag == 'k':\n",
    "    ylabel = r'$M_K$ (mag)'\n",
    "    magrange = [9,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using exitsing folder\n",
      "Log name: TOI1227/log_hybrid_parsec_grp_g_edr3.txt\n"
     ]
    }
   ],
   "source": [
    "#First setup the folder that will contain any output.\n",
    "#If the folder exists, that's OK, with the caveat that it might overwrite things. \n",
    "if os.path.isdir(foldername):\n",
    "    print('Using exitsing folder')\n",
    "else:\n",
    "    print('Making new folder')\n",
    "    os.system('mkdir '+foldername)\n",
    "    \n",
    "##Log with results\n",
    "log_name = foldername+'/log_'+file_endian+'.txt'\n",
    "os.system('rm '+log_name)\n",
    "log = open(log_name,'x')\n",
    "log.write('Log for '+targname+' '+datafile+'\\n')\n",
    "log.write('Fit type: '+fittype)\n",
    "log.write('RUWE cut: '+str(ruwecut)+'\\n')\n",
    "log.write(str(whichgaia)+', '+usecol+' color and '+usemag+' mag \\n')\n",
    "log.write('model grid: '+usegrid+'\\n')\n",
    "log.write('Nsteps: '+str(nsteps)+', Burn: '+str(burn)+ '\\n')\n",
    "log.write('Guess age: '+str(guessage)+'\\n')\n",
    "\n",
    "print('Log name: '+log_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min model age = 1.2, max model age = 49.8 total model points = 21132\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##First we need to read in the model grid and make sure things are in the format we want. \n",
    "if usegrid == 'parsec':\n",
    "    filename = 'Model_grids/parsec_grid_allage.csv'\n",
    "    grid = pd.read_csv(filename, dtype='float32',comment='#')\n",
    "    if usemag == 'g':\n",
    "        modelmag = grid['gaia_gmag'].values\n",
    "    if usemag == 'k':\n",
    "        modelmag = grid['2mass_kmag'].values\n",
    "    if usecol == 'grp':\n",
    "        modelcol = grid['gaia_gmag'].values-grid['gaia_rpmag'].values\n",
    "    if usecol == 'bprp':\n",
    "        modelcol = grid['gaia_bpmag'].values-grid['gaia_rpmag'].values\n",
    "    if usecol == 'gj':\n",
    "        modelcol = grid['gaia_gmag'].values-grid['2mass_jmag'].values\n",
    "    if usecol == 'jk':\n",
    "        modelcol = grid['2mass_jmag'].values-grid['2mass_kmag'].values\n",
    "        \n",
    "    modelg = grid['gaia_gmag'].values\n",
    "    modelr = grid['gaia_rpmag'].values\n",
    "    modelage = grid['age'].values#(10**(grid['logAge'].values))/1e6\n",
    "    \n",
    "    if guessage >= 80:\n",
    "        good = np.where((grid['mass'].values<3) \n",
    "                        & (modelage > guessage/5) \n",
    "                        & (modelage<guessage*5)\n",
    "                        & ((modelg-modelr)<1.5)\n",
    "                        & (modelg < 16)\n",
    "                        & (modelage % 0.5 == 0) ## this is to densensify the grid, only use if guessage is large\n",
    "                       )\n",
    "    else:\n",
    "            good = np.where((grid['mass'].values<3) \n",
    "                    & (modelage > guessage/10) \n",
    "                    & (modelage<guessage*5)\n",
    "                    & ((modelg-modelr)<1.5)\n",
    "                    & (modelg < 16)\n",
    "                    )\n",
    "    modelmag = modelmag[good]\n",
    "    modelcol = modelcol[good]\n",
    "    modelage = modelage[good]\n",
    "    modelg = modelg[good]\n",
    "    modelr = modelr[good]\n",
    "    \n",
    "if usegrid == 'feiden_mag':\n",
    "    filename = 'Model_grids/feiden_grid_mag_interpolated.csv'\n",
    "    grid = pd.read_csv(filename, dtype='float32',comment='#')\n",
    "    if usemag == 'g':\n",
    "        modelmag = grid['gaia_gmag'].values\n",
    "    if usemag == 'k':\n",
    "        modelmag = grid['2mass_kmag'].values\n",
    "    if usecol == 'grp':\n",
    "        modelcol = grid['gaia_gmag'].values-grid['gaia_rpmag'].values\n",
    "    if usecol == 'bprp':\n",
    "        modelcol = grid['gaia_bpmag'].values-grid['gaia_rpmag'].values\n",
    "    if usecol == 'gj':\n",
    "        modelcol = grid['Gmag'].values-grid['2mass_jmag'].values\n",
    "    if usecol == 'jk':\n",
    "        modelcol = grid['2mass_jmag'].values-grid['2mass_kmag'].values\n",
    "    \n",
    "    modelg = grid['gaia_gmag'].values\n",
    "    modelr = grid['gaia_rpmag'].values\n",
    "    modelage = grid['age']##(10**(grid['logAge'].values))/1e6\n",
    "\n",
    "log.write('Min model age = '+str(np.min(modelage))+', max model age = '+str(np.max(modelage))+\n",
    "          ' total model points = '+str(np.size(modelage))+'\\n')\n",
    "          \n",
    "print('Min model age = '+str(np.min(modelage))+', max model age = '+str(np.max(modelage))+\n",
    "          ' total model points = '+str(np.size(modelage))+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This downloads the data from Gaia<br>\n",
    "I'm pretty certain if I took 20m to re-learn SQL I could do this faster with the direct API. But eh...<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 108 targets through Gaia and 2Mass\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n",
      "INFO: Query finished. [astroquery.utils.tap.core]\n"
     ]
    }
   ],
   "source": [
    "sigmaG_0 = 0.0027553202\n",
    "sigmaGBP_0 = 0.0027901700\n",
    "sigmaGRP_0 = 0.0037793818 \n",
    "if os.path.exists(foldername+'/'+datafile+'.csv'):\n",
    "    data = pd.read_csv(foldername+'/'+datafile+'.csv', sep=',')\n",
    "    g = data['G'].values\n",
    "    g_err = data['G_err'].values\n",
    "    bp = data['BP'].values\n",
    "    bp_err = data['BP_err'].values\n",
    "    rp = data['RP'].values\n",
    "    rp_err = data['RP_err'].values\n",
    "    plx = data['plx'].values\n",
    "    eplx = data['eplx'].values\n",
    "    ruwe = data['ruwe'].values\n",
    "    ra = data['ra'].values\n",
    "    dec = data['dec'].values\n",
    "    jm = data['jm'].values\n",
    "    jm_err = data['jm_err'].values\n",
    "    hm = data['hm'].values\n",
    "    hm_err = data['hm_err'].values\n",
    "    km = data['km'].values\n",
    "    km_err = data['km_err'].values\n",
    "    voff = data['voff'].values\n",
    "    sep_deg = data['sep_deg'].values\n",
    "    sep_3d = data['sep_3d'].values\n",
    "    vr_pred = data['vr_pred'].values\n",
    "    vr_obs = data['vr_obs'].values\n",
    "    vr_obserr = data['vr_obserr'].values\n",
    "    ## apply any cuts on the dataset\n",
    "    l = np.where(voff < voffcut)\n",
    "    g = g[l]\n",
    "    g_err = g_err[l]\n",
    "    bp = bp[l]\n",
    "    bp_err = bp_err[l]\n",
    "    rp = rp[l]\n",
    "    rp_err = rp_err[l]\n",
    "    plx = plx[l]\n",
    "    eplx = eplx[l]\n",
    "    ruwe = ruwe[l]\n",
    "    ra = ra[l]\n",
    "    dec = dec[l]\n",
    "    jm = jm[l]\n",
    "    jm_err = jm_err[l]\n",
    "    hm = hm[l]\n",
    "    hm_err = hm_err[l]\n",
    "    km = km[l]\n",
    "    km_err = km_err[l]\n",
    "else:\n",
    "    data=pd.read_csv(datafile+'.csv', sep=',')\n",
    "    ra = data['RA'].values\n",
    "    dec = data['DEC'].values\n",
    "    ##ruwe = data['RUWE'].values\n",
    "    if filetype == 'radec':\n",
    "        voff = np.zeros(np.size(ra))\n",
    "        sep_deg = np.zeros(np.size(ra))\n",
    "        sep_3d = np.zeros(np.size(ra))\n",
    "        vr_pred = np.zeros(np.size(ra))\n",
    "        vr_obs = np.zeros(np.size(ra))\n",
    "        vr_obserr = np.zeros(np.size(ra))\n",
    "    else:\n",
    "        voff = data['Voff(km/s)'].values\n",
    "        sep_deg = data['Sep(deg)'].values\n",
    "        sep_3d = data['3D(pc)'].values\n",
    "        vr_pred = data['Vr(pred)'].values\n",
    "        vr_obs = data['Vr(obs)'].values\n",
    "        vr_obserr = data['Vrerr'].values\n",
    "    \n",
    "    width = u.Quantity(0.001, u.deg)\n",
    "    height = u.Quantity(0.001, u.deg)\n",
    "    if whichgaia == 'edr3':\n",
    "        Gaia.MAIN_GAIA_TABLE = \"gaiaedr3.gaia_source\"\n",
    "    if whichgaia == 'dr2':\n",
    "        Gaia.MAIN_GAIA_TABLE = \"gaiadr2.gaia_source\"\n",
    "\n",
    "    g = []\n",
    "    g_err = []\n",
    "    bp = []\n",
    "    bp_err = []\n",
    "    rp = []\n",
    "    rp_err = []\n",
    "    plx = []\n",
    "    eplx = []\n",
    "    jm = []\n",
    "    jm_err = []\n",
    "    hm = []\n",
    "    hm_err = []\n",
    "    km = []\n",
    "    km_err = []\n",
    "    ruwe = []\n",
    "    ii = 0\n",
    "    v = Vizier(columns=[\"*\", \"+_r\"], catalog=\"II/246\")\n",
    "    rad = \"6s\"\n",
    "    print('Running',np.size(ra),'targets through Gaia and 2Mass')\n",
    "    for r,d in zip(ra,dec):\n",
    "        ## 2mass first:\n",
    "        coord = SkyCoord(ra=r, dec=d, unit=(u.degree, u.degree), frame='icrs')\n",
    "        result = v.query_region(coord,radius=rad)\n",
    "        if np.size(result) >= 1:\n",
    "            jm = np.append(jm,(result[0]['Jmag'][0]))\n",
    "            jm_err = np.append(jm_err,(result[0]['e_Jmag'][0]))\n",
    "            hm = np.append(hm,(result[0]['Hmag'][0]))\n",
    "            hm_err = np.append(hm_err,(result[0]['e_Hmag'][0]))\n",
    "            km = np.append(km,(result[0]['Kmag'][0]))\n",
    "            km_err = np.append(km_err,(result[0]['e_Kmag'][0]))\n",
    "        else:\n",
    "            jm = np.append(jm,np.nan)\n",
    "            jm_err = np.append(jm_err,np.nan)\n",
    "            hm = np.append(hm,np.nan)\n",
    "            hm_err = np.append(hm_err,np.nan)\n",
    "            km = np.append(km,np.nan)\n",
    "            km_err = np.append(km_err,np.nan)\n",
    "        \n",
    "        \n",
    "        catalog_data = Gaia.query_object_async(coordinate=coord, width=width, height=height,verbose=False)\n",
    "        if np.size(catalog_data) >= 1:\n",
    "            bp = np.append(bp,catalog_data['phot_bp_mean_mag'][0])\n",
    "            bp_err = np.append(bp_err,(np.sqrt((-2.5/np.log(10)*catalog_data['phot_bp_mean_flux_error']/catalog_data['phot_bp_mean_flux'])**2 + sigmaG_0**2))[0])\n",
    "            g = np.append(g,catalog_data['phot_g_mean_mag'][0])\n",
    "            g_err = np.append(g_err,(np.sqrt((-2.5/np.log(10)*catalog_data['phot_g_mean_flux_error']/catalog_data['phot_g_mean_flux'])**2 + sigmaG_0**2))[0])\n",
    "            rp = np.append(rp,catalog_data['phot_rp_mean_mag'][0])\n",
    "            rp_err = np.append(rp_err,(np.sqrt((-2.5/np.log(10)*catalog_data['phot_rp_mean_flux_error']/catalog_data['phot_rp_mean_flux'])**2 + sigmaG_0**2))[0])\n",
    "            plx = np.append(plx,catalog_data['parallax'][0])\n",
    "            eplx = np.append(eplx,catalog_data['parallax_error'][0])\n",
    "            ruwe = np.append(ruwe,catalog_data['ruwe'][0])\n",
    "\n",
    "            \n",
    " \n",
    "            \n",
    "        else:\n",
    "            print('failed ',r,d)\n",
    "            bp = np.append(bp,np.nan)\n",
    "            bp_err = np.append(bp_err,np.nan)\n",
    "            g = np.append(g,np.nan)\n",
    "            g_err = np.append(g_err,np.nan)\n",
    "            rp = np.append(rp,np.nan)\n",
    "            rp_err = np.append(rp_err,np.nan)\n",
    "            plx = np.append(plx,np.nan)\n",
    "            eplx = np.append(eplx,np.nan)\n",
    "        ii+=1\n",
    "        #print(bp[-1]-rp[-1],g[-1]-km[-1],jm[-1]-km[-1])\n",
    "    print('saving data to '+datafile+'.csv')\n",
    "    df = pd.DataFrame({\"G\":g,\"G_err\":g_err,\"BP\":bp,\"BP_err\":bp_err,\"RP\":rp,\"RP_err\":rp_err,\n",
    "                       \"plx\":plx,\"eplx\":eplx,\"ruwe\":ruwe,\"ra\":ra,\"dec\":dec,\n",
    "                       \"jm\":jm,\"jm_err\":jm_err,\"hm\":hm,\"hm_err\":hm_err,\"km\":km,\"km_err\":km_err,\n",
    "                       \"voff\":voff, \"sep_deg\":sep_deg,\"sep_3d\":sep_3d,\"vr_pred\":vr_pred,\"vr_obs\":vr_obs,\"vr_obserr\":vr_obserr\n",
    "                       })\n",
    "    df.to_csv(foldername+'/'+datafile+\".csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## UGHH, can you get rid of this damned \"INFO: Query finished.\" crap?\n",
    "## it's annoying!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## here is where we will correct for the parallax systematics from El-Badry\n",
    "## technically only good for RUWE<1.4\n",
    "a = 0.21\n",
    "g0 = 12.65\n",
    "b = 0.90 \n",
    "p0 = 1.141\n",
    "p1 = 0.0040\n",
    "p2 = -0.00062\n",
    "f = a*np.exp(-1*(g-g0)**2/b**2)+p0+ p1*g+ p2*g**2\n",
    "eplx*=f\n",
    "\n",
    "## select which observational parameters to use \n",
    "if usecol == 'grp':\n",
    "    col = g-rp\n",
    "    colerr = np.sqrt(np.square(g_err)+np.square(rp_err))\n",
    "    coltest = [0.0,0.2,0.4,0.8] ## reasonable range of colors\n",
    "if usecol == 'bprp':\n",
    "    col = bp-rp\n",
    "    colerr = np.sqrt(np.square(bp_err)+np.square(rp_err))\n",
    "    coltest = [0.6,1.6,2.7,3.5]\n",
    "if usecol == 'gj':\n",
    "    col = g-jm\n",
    "    colerr = np.sqrt(np.square(g_err)+np.square(jm_err))\n",
    "    coltest = [0.5,1.5,2.5,3.5]\n",
    "if usecol == 'jk':\n",
    "    col = jm-km\n",
    "    colerr = np.sqrt(np.square(jm_err)+np.square(km_err))\n",
    "    coltest = [-0.1,0.1,0.3,0.5]\n",
    "if usemag == 'k':\n",
    "    mag = km-5.0*(np.log10(1000./plx)-1)\n",
    "    tmp = eplx*(5./(plx*np.log(10.)))\n",
    "    magerr = np.sqrt(km_err**2 + (tmp)**2) \n",
    "if usemag == 'g':\n",
    "    mag = g-5.0*(np.log10(1000./plx)-1)\n",
    "    tmp = eplx*(5./(plx*np.log(10.)))\n",
    "    magerr = np.sqrt(g_err**2 + (tmp)**2) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Consider removing this part of the code depending on what kinda plots you want.\n",
    "\n",
    "## change the plot range based on the data\n",
    "## take the smaller (narrower window) of the two\n",
    "l = np.where(np.isfinite(mag))\n",
    "buffer = 0.1\n",
    "if np.min(col[l])-buffer > colrange[0]:\n",
    "    colrange[0] = np.min(col[l])-buffer\n",
    "if np.max(col[l])+buffer < colrange[1]:\n",
    "    colrange[1] = np.max(col[l])+buffer\n",
    "if np.max(mag[l])+buffer < magrange[0]:\n",
    "    magrange[0] = np.max(mag[l])+buffer\n",
    "if np.min(mag[l])-buffer > magrange[1]:\n",
    "    magrange[1] = np.min(mag[l])-buffer\n",
    "print(np.min(mag[l]),np.max(mag))\n",
    "print(colrange,magrange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catcord = SkyCoord(ra=ra*u.degree, dec=dec*u.degree, frame='icrs')\n",
    "if 'targcoord' in locals():\n",
    "    print('cat')\n",
    "    l = np.where(targcoord.separation(catcord) == np.min(targcoord.separation(catcord)))\n",
    "else:\n",
    "    l = 0\n",
    "    targcoord = SkyCoord(ra=ra[0]*u.degree, dec=dec[0]*u.degree, frame='icrs')\n",
    "    \n",
    "fig, axes = plt.subplots(figsize=(10, 7), sharex=True)\n",
    "if (targcoord.separation(catcord))[l] < 5*u.arcsec:\n",
    "    targcol = col[l]\n",
    "    targmag = mag[l]   \n",
    "    axes.scatter(targcol,targmag,label=targname,marker='*',zorder=4,color='black',s=150)\n",
    "else:\n",
    "    targcol = np.NAN\n",
    "    targmag = np.NAN\n",
    "    \n",
    "axes.errorbar(col,mag,xerr=colerr,yerr=magerr,fmt=' ',marker='.')\n",
    "axes.set_ylim(magrange[0],magrange[1])\n",
    "axes.set_xlim(colrange[0],colrange[1])\n",
    "\n",
    "for age in np.array([guessage*0.7,guessage,guessage*1.3]):\n",
    "    l = np.squeeze(np.where(np.abs(modelage-age) == np.min(np.abs(modelage-age))))\n",
    "    axes.plot(modelcol[l],modelmag[l],label=str(int(age))+'Myr')\n",
    "\n",
    "grp_red = [-0.18,-0.08,0.02,0.12,0.22,0.32,0.42 ,0.52 ,0.62 ,0.72 ,0.82,0.92 ,1.02 ,1.12 ,1.22,1.32 ,1.42]\n",
    "RG = [3.112,3.05 ,2.99 ,2.961,2.90 ,2.80 ,2.68 ,2.570,2.507,2.397,2.30 ,2.211,2.157,2.057,1.930,1.852,1.818]\n",
    "RRP = [1.938,1.930,1.923,1.919,1.908,1.90,1.881,1.865,1.860,1.842,1.823,1.796,1.769,1.735,1.687,1.656,1.641]\n",
    "RBP = [3.670,3.59,3.53,3.504,3.47,3.40,3.34,3.257,3.206,3.124,3.04,3.000,3.000,2.965,2.944,2.924,2.912]\n",
    "fg = interpolate.interp1d(grp_red,RG,fill_value='extrapolate')\n",
    "frp = interpolate.interp1d(grp_red,RRP,fill_value='extrapolate')\n",
    "fbp = interpolate.interp1d(grp_red,RBP,fill_value='extrapolate')\n",
    "if usecol == 'grp':\n",
    "    mag1corr = fg\n",
    "    mag2corr = frp\n",
    "if usecol == 'bprp':\n",
    "    mag1corr = fbp\n",
    "    mag2corr = frp\n",
    "magcorr = fg\n",
    "modelgrp = modelg-modelr\n",
    "age = guessage\n",
    "\n",
    "bounds = [np.min(modelmag[l]),np.max(modelmag[l]),np.min(modelcol[l]),np.max(modelcol[l])]\n",
    "if usecol == 'jk':\n",
    "    bounds = [np.min(modelmag[l])+0.1,np.max(modelmag[l])-0.1,np.min(modelcol[l])+0.1,np.max(modelcol[l])+0.1]\n",
    "\n",
    "\n",
    "l = np.squeeze(np.where((np.abs(modelage-age) == np.min(np.abs(modelage-age))) & (modelg > bounds[0]) & (modelg < bounds[1]) ))\n",
    "for EBV in np.array([0.05,0.10,0.20]):\n",
    "    axes.plot(modelcol[l]+EBV*(mag1corr(modelgrp[l])-mag2corr(modelgrp[l])),\n",
    "              modelmag[l]+EBV*magcorr(modelgrp[l]),'--',\n",
    "              label=str(int(age))+'Myr; E(B-V)='+str(EBV))\n",
    "axes.legend(fontsize=14)\n",
    "axes.set_xlabel(xlabel)\n",
    "axes.set_ylabel(ylabel)\n",
    "fig.savefig(foldername+'/TestCMD1'+file_endian+'.pdf',dpi=400)\n",
    "\n",
    "## define the reasonable bounds for the model interpolation and run a test set\n",
    "l = np.squeeze(np.where(np.abs(modelage-guessage) == np.min(np.abs(modelage-guessage))))\n",
    "f = interpolate.interp1d(modelcol[l],modelmag[l],fill_value='extrapolate')\n",
    "mag_predict = f(coltest)\n",
    "log.write('Predicted mags (check for weird values or NaN: '+str(mag_predict)+'\\n')\n",
    "log.write('Model mag and color limits for the given age:'+'\\n')\n",
    "log.write(str(np.min(modelmag[l]))+' '+str(np.max(modelmag[l]))+' '+str(np.min(modelcol[l]))+' '+str(np.max(modelcol[l])))\n",
    "log.write('\\n')\n",
    "\n",
    "good = np.squeeze(np.where((mag > bounds[0]) & \n",
    "                        (mag < bounds[1]) & \n",
    "                        (col > bounds[2]) & \n",
    "                        (col < bounds[3]) & \n",
    "                        (ruwe < ruwecut) & \n",
    "                        (np.abs(col) > 0.00001) &\n",
    "                        np.isfinite(col))\n",
    "                 )\n",
    "\n",
    "plt.scatter(col,mag,alpha=0.5)\n",
    "plt.errorbar(col[good],mag[good],xerr=colerr[good],yerr=magerr[good],marker='.',fmt=' ',alpha=1,color='g')\n",
    "plt.xlim(colrange[0],colrange[1])\n",
    "plt.ylim(magrange[0],magrange[1])\n",
    "plt.xlabel(xlabel)\n",
    "plt.ylabel(ylabel)\n",
    "plt.savefig(foldername+'/TestCMD2'+file_endian+'.pdf',dpi=400)    \n",
    "    \n",
    "    \n",
    "col1 = np.array(col[good])\n",
    "mag1 = np.array(mag[good])\n",
    "colerr1 = np.array(colerr[good])\n",
    "magerr1 = np.array(magerr[good])\n",
    "ra1 = np.array(ra[good])\n",
    "dec1 = np.array(dec[good])\n",
    "ruwe1 = np.array(ruwe[good])\n",
    "mask = np.ones(len(data), np.bool)\n",
    "mask[good] = 0\n",
    "\n",
    "bad = mask\n",
    "col2 = np.array(col[bad])\n",
    "mag2 = np.array(mag[bad])\n",
    "colerr2 = np.array(colerr[bad])\n",
    "magerr2 = np.array(magerr[bad])\n",
    "ra2 = np.array(ra[bad])\n",
    "dec2 = np.array(dec[bad])\n",
    "ruwe2 = np.array(ruwe[bad])\n",
    "bp2 = np.array(bp[bad])\n",
    "rp2 = np.array(rp[bad])\n",
    "g2 = np.array(g[bad])\n",
    "\n",
    "## write to a file the rejected sources for manual inspection:\n",
    "baddies_name = foldername+'/baddies'+file_endian+'.txt'\n",
    "##   RA, Dec, g, Bp, Rp, Mag, Col, Ruwe\n",
    "fmt1 = \"%11.7f %11.7f %6.3f %6.3f %6.3f %6.3f %6.3f %6.3f\"\n",
    "os.system('rm '+baddies_name)\n",
    "baddies = open(baddies_name,'x')\n",
    "baddies.write('RA           DEC          Gmag   Bp     Rp     Mg     Col    RUWE  \\n')\n",
    "for i in np.arange(np.size(ra2)):\n",
    "    j = int(np.squeeze(i))\n",
    "    baddies.write(fmt1 % (ra2[j],dec2[j],g2[j],bp2[j],rp2[j],mag2[j],col2[j],ruwe2[j]))\n",
    "    baddies.write(\"\\n\")\n",
    "    \n",
    "baddies.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it's worth eye-balling that plot. You want to see if the tool removed a lot of the funny stars. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ln_prior(theta,fittype):\n",
    "    age, EBV, Pb, Yb, Vb, sys = theta\n",
    "    if (fittype == 'normal') or (fittype == 'hybrid'):\n",
    "        if 0 < age < 500 and 0 <= Pb <= 0.9 and -50 <= Yb <= 50 and 0 <= Vb <= 50 and sys >= 0 and 1.0 >= EBV >= -0.15:\n",
    "            sigma2 = 0.07**2\n",
    "            val = 0\n",
    "            p1 = (1. / np.sqrt(2 * np.pi * sigma2)) * np.exp(-(sys-val)**2/(2 * sigma2))\n",
    "#             sigma2 = 0.05**2\n",
    "#             val = 0.0\n",
    "#             p2 = (1. / np.sqrt(2 * np.pi * sigma2)) * np.exp(-(EBV-val)**2/(2 * sigma2))\n",
    "            return np.log(p1)#+np.log(p2)\n",
    "    if fittype == 'binary':\n",
    "        if 0 < age < 500 and 0 <= Pb <= 0.9 and -1 <= Yb <= 0 and 0 <= Vb <= 1 and sys >= 0 and 1.0 >= EBV >= -0.15:\n",
    "            sigma2 = 0.03**2\n",
    "            val = 0\n",
    "            p1 = (1. / np.sqrt(2 * np.pi * sigma2)) * np.exp(-(sys-val)**2/(2 * sigma2))\n",
    "            sigma2 = 0.1**2\n",
    "            val = -0.4\n",
    "            p2 = (1. / np.sqrt(2 * np.pi * sigma2)) * np.exp(-(Yb-val)**2/(2 * sigma2))\n",
    "            return np.log(p1)+np.log(p2)\n",
    "    return -np.inf\n",
    "\n",
    "def ln_likelihood(theta, fittype, mag1corr, mag2corr, magcorr, modelgrp, modelage, modelmag, modelcol, \n",
    "                  col, mag, colerr, magerr):\n",
    "    age, EBV, Pb, Yb, Vb, sys = theta\n",
    "    \n",
    "    l = np.squeeze(np.where(np.abs(modelage-age) == np.min(np.abs(modelage-age))))\n",
    "    redcol = modelcol[l]+EBV*(mag1corr(modelgrp[l])-mag2corr(modelgrp[l]))\n",
    "    redmag = modelmag[l]+EBV*magcorr(modelgrp[l])\n",
    "    f = interpolate.interp1d(redcol,redmag,fill_value='extrapolate')\n",
    "    mag_predict = f(col)\n",
    "    mag_predict2 = f(col+colerr)\n",
    "    err2 = np.abs(mag_predict2-mag_predict)\n",
    "\n",
    "    sigma2 = magerr**2+err2**2+sys**2\n",
    "    p_fg = ((1-Pb) / np.sqrt(2 * np.pi * sigma2)) * np.exp(-(mag-mag_predict)**2/(2 * sigma2))\n",
    "    ## this needs to be fixed\n",
    "    ## separate out the 'hybrid' case. In that case, do not apply the reddening correction to the \n",
    "    ## outlier population. It should apply to the binary population. \n",
    "    if fittype == 'hybrid':\n",
    "        f = interpolate.interp1d(modelcol[l],modelmag[l],fill_value='extrapolate')\n",
    "        mag_predict_nored = f(col)\n",
    "        p_bg = (Pb / np.sqrt(2 * np.pi * (Vb + sigma2))) * np.exp(-((mag-mag_predict_nored)-Yb)**2/(2 * (Vb + sigma2)))        \n",
    "    if fittype == 'binary':\n",
    "        p_bg = (Pb / np.sqrt(2 * np.pi * (Vb + sigma2))) * np.exp(-((mag-mag_predict)-Yb)**2/(2 * (Vb + sigma2)))\n",
    "    if fittype == 'normal':\n",
    "        p_bg = (Pb / np.sqrt(2 * np.pi * (Vb + sigma2))) * np.exp(-(mag-Yb)**2/(2 * (Vb + sigma2)))\n",
    "        \n",
    "    output = np.sum(np.log(p_fg + p_bg))\n",
    "    if np.isfinite(output):\n",
    "        return output\n",
    "    else:\n",
    "        return -np.inf\n",
    "    \n",
    "def ln_posterior(theta, fittype, mag1corr, mag2corr, \n",
    "                 magcorr, modelgrp, modelage, modelmag, modelcol, \n",
    "                 col, mag, colerr, magerr):\n",
    "    ln_p = ln_prior(theta, fittype)\n",
    "    if not np.isfinite(ln_p):\n",
    "        return -np.inf\n",
    "    return ln_p + ln_likelihood(theta, fittype, mag1corr, mag2corr, \n",
    "                                magcorr, modelgrp, modelage, modelmag, modelcol, \n",
    "                                col, mag, colerr, magerr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fittype == 'binary' or fittype == 'hybrid':\n",
    "    initial_guesses = [guessage, 0.1, 0.1, -0.3, 1, 0.01]\n",
    "else:\n",
    "    initial_guesses = [guessage, 0.1, 0.1, 10, 5, 0.01]\n",
    "    \n",
    "ndim = np.size(initial_guesses)\n",
    "pos0 = []\n",
    "counter = 0\n",
    "randomizer = [1, 0.001, 0.005, 0.1, 0.1,0.001]\n",
    "nwalkers = ndim*5\n",
    "\n",
    "while len(pos0) < nwalkers:\n",
    "    counter+=1\n",
    "    if counter > 5000:\n",
    "        print('failed to initialize walkers, check the initial conditions and/or input data')\n",
    "        break \n",
    "    trial = initial_guesses + randomizer * np.random.randn(ndim)\n",
    "    age, EBV, Pb, Yb, Vb, sys = trial\n",
    "    lp = ln_posterior(trial, fittype, mag1corr, mag2corr, \n",
    "                      magcorr, modelgrp, modelage, modelmag, modelcol, \n",
    "                      col1, mag1, colerr1, magerr1)\n",
    "    if np.isfinite(lp):\n",
    "        pos0.append(trial)\n",
    "#print(trial)\n",
    "#print(ln_prior(trial,fittype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = foldername+'/'+\"mix_ages_backend.h5\"\n",
    "backend = emcee.backends.HDFBackend(filename)\n",
    "os.system(\"rm \"+filename)\n",
    "sampler = emcee.EnsembleSampler(nwalkers, ndim, ln_posterior, backend=backend, \n",
    "                                args=(fittype, mag1corr, mag2corr, magcorr, modelgrp, modelage, modelmag, modelcol,col1, mag1, colerr1, magerr1), threads=8)\n",
    "sampler.run_mcmc(pos0, nsteps, progress=True)\n",
    "print('done with mcmc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plotting!!!\n",
    "\n",
    "samples = sampler.get_chain(discard=burn)\n",
    "fig, axes = plt.subplots(ndim, figsize=(10, 7), sharex=True)\n",
    "labels = [r'Age (Myr)',r'$E(B-V)$', r'$P_B$',r'$Y_B$ (mag)',r'$V_B$ (mag)','f (mag)']\n",
    "for i in range(ndim):\n",
    "     ax = axes[i]\n",
    "     ax.plot(samples[:, :, i], \"k\", alpha=0.3)\n",
    "     ax.set_xlim(0, len(samples))\n",
    "     ax.set_ylabel(labels[i])\n",
    "     ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "        \n",
    "fig.set_rasterized(True)\n",
    "fig.savefig(foldername+'/walker'+file_endian+'.pdf',dpi=400)\n",
    "\n",
    "          \n",
    "## check the autocorrelation time (this is to check for convergence)\n",
    "tau = sampler.get_autocorr_time(tol=0)\n",
    "#print('Tau for each parameter. If any are >', nsteps//50,' then run a longer chain.')\n",
    "if np.any(tau > nsteps//50):\n",
    "    print('You need to run a longer chain')\n",
    "    print(np.max(tau),nsteps//50)\n",
    "    log.write('You need to run a longer chain:\\n')\n",
    "    log.write(str(np.max(tau))+','+str(nsteps//50))\n",
    "else:\n",
    "    print('Chain at least 50x the autocorrelation time.',int((np.max(tau)*50)//1),nsteps)\n",
    "    log.write('Chain at least 50x the autocorrelation time. '+str(int((np.max(tau)*50)//1))+' '+str(nsteps)+'\\n')\n",
    "    \n",
    "## flatten (i.e., dump the separate walkers)\n",
    "flat_samples = sampler.get_chain(discard=burn, thin=5, flat=True)\n",
    "\n",
    "fig = corner.corner( \n",
    "    flat_samples,show_titles=True, labels=labels,range=[0.9995,0.9995,0.9995,0.9995,0.9995,0.9995],\n",
    "    smooth=1,\n",
    "    fill_contours=True, plot_datapoints=False,title_kwargs={\"fontsize\": 11},title_fmt='.3f',\n",
    "    hist_kwargs={\"linewidth\": 2.5},levels=[(1-np.exp(-0.5)),(1-np.exp(-2)),(1-np.exp(-4.5))]\n",
    ");\n",
    "plt.savefig(foldername+'/corner'+file_endian+'.pdf',dpi=400)\n",
    "\n",
    "\n",
    "from IPython.display import display, Math\n",
    "\n",
    "for i in range(ndim):\n",
    "    mcmc = np.percentile(flat_samples[:, i], [16, 50, 84])\n",
    "    q = np.diff(mcmc)\n",
    "    txt = \"\\mathrm{{{3}}} = {0:.3f}_{{-{1:.3f}}}^{{{2:.3f}}}\"\n",
    "    txt = txt.format(mcmc[1], q[0], q[1], labels[i])\n",
    "    log.write(txt + '\\n')\n",
    "    display(Math(txt))\n",
    "\n",
    "## identify the FPs\n",
    "\n",
    "## this is detailed in DFM's guide, he uses \"blob\" which I could not get to work\n",
    "## the basic idea is that we pull out a random set of fit parameters from the mcmc, assign the \n",
    "## resulting outlier probs to each point, and save those to post_prob (cumulative). Then divide by the\n",
    "## total number of random samples we pulled. This gives us the \"average\" probability that a star is a\n",
    "## member. \n",
    "\n",
    "    \n",
    "##Note that \"outliers\" are mostly non-members, but because the models are not perfect, could easily\n",
    "## just be stars where the models failed\n",
    "## I had initially hoped this would also catch the binaries, but that does not appear to be happening.\n",
    "## Instead, the code is handling the binaries by increasing \"f\" to include most of the binary population.\n",
    "## this means that the age is probably underestimated. I don't have a simple solution for this right now. \n",
    "## we might have to explicitly model the binaries or force f to be smaller. \n",
    "norm = 0.0\n",
    "post_prob = np.zeros(len(col1))\n",
    "elements = 2000\n",
    "for i in range(elements):\n",
    "    index = random.randrange(0, np.size(flat_samples[:,0])-1)\n",
    "    age,EBV, Pb,Yb,Vb,sys = flat_samples[index,:]\n",
    "    l = np.squeeze(np.where(np.abs(modelage-age) == np.min(np.abs(modelage-age))))\n",
    "    redcol = modelcol[l]+EBV*(mag1corr(modelgrp[l])-mag2corr(modelgrp[l]))\n",
    "    redmag = modelmag[l]+EBV*magcorr(modelgrp[l])\n",
    "    f = interpolate.interp1d(redcol,redmag,fill_value='extrapolate')\n",
    "    mag_predict = f(col1)\n",
    "    mag_predict2 = f(col1+colerr1)\n",
    "    err2 = np.abs(mag_predict2-mag_predict)\n",
    "    sigma2 = magerr1**2+err2**2+sys**2\n",
    "    p_fg = ((1-Pb) / np.sqrt(2 * np.pi * sigma2)) * np.exp(-(mag1-mag_predict)**2/(2 * sigma2))\n",
    "    ll_fg = np.log(p_fg)\n",
    "    p_bg = (Pb / np.sqrt(2 * np.pi * (Vb + sigma2))) * np.exp(-((mag1-mag_predict)-Yb)**2/(2 * (Vb + sigma2)))\n",
    "    \n",
    "    ll_bg = np.log(p_bg)\n",
    "    post_prob += np.exp(ll_fg - np.logaddexp(ll_fg, ll_bg))\n",
    "post_prob/=elements\n",
    "outliers = np.where(post_prob < 0.5)##50% chance of being outliers\n",
    "\n",
    " \n",
    "targsize = 200\n",
    "## Take out the fit parameters. Note I'm lazily using median=best-fit, which is fine for \n",
    "## such a simple relation, but not necessarily OK generally. To get the best fit, use the likelihood\n",
    "## values from the MCMC chain (check emcee docs).\n",
    "params = np.array([0.,0.,0.,0.,0.,0.])\n",
    "for i in range(ndim):\n",
    "    params[i] = np.percentile(flat_samples[:, i],[50])\n",
    "    age, EBV, Pb, Yb, Vb, sys = params\n",
    "\n",
    "\n",
    "fig,ax1 = plt.subplots(figsize=(9,5))\n",
    "## another way to do this is to color the points by outlier prob to see how the weighting works out\n",
    "ec = ax1.scatter(col1,mag1,c=1.-post_prob,vmin=0.0 , vmax=1 , cmap='gray',s=50,zorder=3,alpha=0.9)\n",
    "cb = plt.colorbar(ec , ax=ax1)\n",
    "ax1.scatter(col1,mag1,marker='.',edgecolors='blue',facecolors='none',s=150,label='Stars included in model',zorder=3)\n",
    "if np.size(col2) > 1:\n",
    "    ax1.scatter(col2,mag2,marker='s',edgecolors='royalblue',alpha=0.6,s=25,label='Stars excluded from model',zorder=0)\n",
    "cb.set_label(label='MCMC outlier probability',fontsize=14)\n",
    "    \n",
    "elements2 = 100\n",
    "for i in range(elements2):\n",
    "    index = random.randrange(0, np.size(flat_samples[:,0])-1)\n",
    "    age,EBV, Pb,Yb,Vb,sys = flat_samples[index,:]\n",
    "    l = np.squeeze(np.where(np.abs(modelage-age) == np.min(np.abs(modelage-age))))\n",
    "    redcol = modelcol[l]+EBV*(mag1corr(modelgrp[l])-mag2corr(modelgrp[l]))\n",
    "    redmag = modelmag[l]+EBV*magcorr(modelgrp[l])\n",
    "    ax1.plot(redcol,redmag,label='_Model',color='green',alpha=2./elements2,zorder=1)\n",
    "ax1.plot([0],[0],label='Model Samples',color='green',alpha=1)\n",
    "ax1.scatter(targcol,targmag,marker='*',s=50,label=targname,color='cyan',zorder=5)\n",
    "ax1.legend(fontsize=13)\n",
    "ax1.set_xlabel(xlabel , fontsize=16)\n",
    "ax1.set_ylabel(ylabel, fontsize=16)\n",
    "ax1.set_xlim(colrange[0],colrange[1])\n",
    "ax1.set_ylim(magrange[0],magrange[1])\n",
    "\n",
    "ax2 = ax1.twiny()\n",
    "ax2.set_xlim(ax1.get_xlim())\n",
    "if usecol == 'bprp':\n",
    "    spttickvals = np.array([ -0.037 , 0.377 , 0.782 , 0.983 , 1.84 , 2.50 , 3.35 , 4.65 ])\n",
    "if usecol == 'grp':\n",
    "    spttickvals = np.array([ -0.020 , 0.230 , 0.439 , 0.56 , 0.92 , 1.13 , 1.33 , 1.52 ])  \n",
    "sptticklabs = np.array([ 'A0' , 'F0' , 'G0' , 'K0' , 'M0' , 'M3' , 'M5' , 'M7' ])\n",
    "xx = np.where( (spttickvals >= colrange[0]) & (spttickvals <= colrange[1]))\n",
    "ax2.set_xticks(spttickvals[xx])\n",
    "ax2.set_xticklabels( sptticklabs[xx] )\n",
    "ax2.set_xlabel('Spectral Type' , fontsize=16, labelpad=15)\n",
    "ax2.tick_params(axis='both',which='major',labelsize=12)\n",
    "fig.savefig(foldername+'/CMDcoloroutlier'+file_endian+'.pdf',dpi=400, bbox_inches='tight')\n",
    "\n",
    "##write the results to a file\n",
    "\n",
    "## write to a file the rejected sources for manual inspection:\n",
    "prob_out = foldername+'/Probs_'+file_endian+'.txt'\n",
    "##   RA, Dec, g, Bp, Rp, Mag, Col, Ruwe\n",
    "fmt1 = \"%11.7f %11.7f %6.3f %6.3f %6.3f\"\n",
    "os.system('rm '+prob_out)\n",
    "prob = open(prob_out,'x')\n",
    "prob.write('RA           DEC          color  Mg   Prob  \\n')\n",
    "for i in np.arange(np.size(ra1)):\n",
    "    j = int(np.squeeze(i))\n",
    "    prob.write(fmt1 % (ra1[j],dec1[j],col1[j],mag1[j],post_prob[j]))\n",
    "    prob.write(\"\\n\")\n",
    "    \n",
    "prob.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### temporary\n",
    "# flat_samples = sampler.get_chain(discard=burn, thin=5, flat=True)\n",
    "# fig = corner.corner( \n",
    "#     flat_samples[:,0:5],show_titles=True, labels=labels[0:5],range=[0.995,0.995,0.999,0.999,0.999],\n",
    "#     smooth=1,\n",
    "#     fill_contours=True, plot_datapoints=False,title_kwargs={\"fontsize\": 11},title_fmt='.3f',\n",
    "#     hist_kwargs={\"linewidth\": 2.5},levels=[(1-np.exp(-0.5)),(1-np.exp(-2)),(1-np.exp(-4.5))]\n",
    "# );\n",
    "# plt.savefig(foldername+'/corner'+file_endian+'_nof.pdf',dpi=400)\n",
    "# #############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
